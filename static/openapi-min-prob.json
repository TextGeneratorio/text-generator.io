{
  "openapi": "3.0.2",
  "info": {
    "title": "Generate Text API",
    "description": "Generate text, create chat bots, perform question answering, classification, language translation, prediction across a variety of domains via 'prompt engineering' asking questions in a familiar way to human conversation. \n Under the hood we use very large language models trained on broad human language.  \n * control stopping criteria and cost\n * `max_length` for a maximum amount of tokens \n * `max_sentences` for setting a max number of sentences, good for conversational agents or when you know how many sentences should be generated\n * `stopping_sequences` a list of sequences that once generated signal the end of text generation, give some examples of when these should appear in your prompt, these wont be output at the end if used to stop. \n * control the variety of results \n * get more results with `number_of_results`\n * higher `top_p`, lower `top_k` for high variety/creativity \n * low `top_p` and high `top_k` for consistency\n * low `temperature` for consistency, high for creativity\n * when generating shorter sequences you may want to choose settings that give higher consistency and are more likely, when generating long sequences you may want to use settings that are give more surprise/creativity, defaults should work well for both.",
    "version": "1"
  },
  "paths": {
    "/api/v1/generate": {
      "post": {
        "summary": "Generate text",
        "operationId": "generate_route_api_v1_generate_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/GenerateParams"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/GenerateResponse"
                },
                "example": [
                  {
                    "generated_text": "Hello world! How are you? I'm fine, Thanks for asking.",
                    "stop_reason": "max_sentences"
                  }
                ]
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "GenerateParams": {
        "title": "GenerateParams",
        "required": [
          "text"
        ],
        "type": "object",
        "properties": {
          "text": {
            "title": "Text",
            "type": "string",
            "description": "Text input, predicts what comes afterward",
            "example": "Hello world! How are you? "
          },
          "number_of_results": {
            "title": "Number Of Results",
            "type": "integer",
            "default": 1,
            "description": "Number of results to return",
            "example": 1
          },
          "max_length": {
            "title": "Max Length",
            "type": "integer",
            "default": 100,
            "description": "Maximum length of generated text, in tokens"
          },
          "max_sentences": {
            "title": "Num Sentences",
            "type": "integer",
            "default": 0,
            "description": "Maximum number of sentences to generate, 0 for any amount of sentences"
          },
          "min_probability": {
            "title": "Min Probability",
            "type": "number",
            "description": "Minimum probability required during generation, higher causes the output to stop sooner when it encounters a low probability token/phrase, used when you want the model to stop instead of going off topic or saying wrong things, useful for short generation like autocomplete",
            "default": 0.0
          },
          "stop_sequences": {
            "title": "Stop Sequences",
            "type": "array",
            "items": {
              "type": "string"
            },
            "default": ["?", "!", "."],
            "description": "Sequences to stop generating text after seeing, these are not returned in the results"
          },
          "top_p": {
            "title": "Top P",
            "type": "number",
            "default": 0.9,
            "description": "Probability threshold for token selection, higher means higher diversity results"
          },
          "top_k": {
            "title": "Top K",
            "type": "integer",
            "default": 40,
            "description": "Number of top-probability tokens to keep when deciding which token to use, higher means higher diversity"
          },
          "temperature": {
            "title": "Temperature",
            "type": "number",
            "default": 0.7,
            "description": "Temperature of the generated text, higher means more diversity, 0 for greedy search"
          },
          "seed": {
            "title": "Seed",
            "type": "integer",
            "default": 0,
            "description": "Seed controlling randomness, set a seed for a reproducible result, otherwise results are not reproducible and can be different for the same input if you make multiple requests"
          }
        }
      },
      "GenerateResponse": {
        "title": "GenerateResponse",
        "required": [
          "text"
        ],
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "generated_text": {
              "title": "Text",
              "type": "string",
              "description": "Text input, predicts what comes afterward",
              "example": "Hello world! How are you? "
            },
            "stop_reason": {
              "title": "stop_reason",
              "type": "integer",
              "default": 1,
              "description": "the stopping sequence seen that triggered stopping or a different stop reason \"max_length\" or \"max_sentences\" or \"min_probability\"",
              "example": "max_length"
            }
          }
        }
      },
      "HTTPValidationError": {
        "title": "HTTPValidationError",
        "type": "object",
        "properties": {
          "detail": {
            "title": "Detail",
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            }
          }
        }
      },
      "ValidationError": {
        "title": "ValidationError",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "type": "object",
        "properties": {
          "loc": {
            "title": "Location",
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "msg": {
            "title": "Message",
            "type": "string"
          },
          "type": {
            "title": "Error Type",
            "type": "string"
          }
        }
      }
    }
  }
}
